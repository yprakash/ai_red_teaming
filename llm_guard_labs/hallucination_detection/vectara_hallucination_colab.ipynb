{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-2zSEu6y84Y",
        "outputId": "3d2d0634-5499-4098-bba1-3dc13e814bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-xmi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-xmi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "from transformers import (\n",
        "    pipeline,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14L4KE__y_4r",
        "outputId": "45f51c83-44c8-4d1c-eb9c-d332f1b7b2a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"vectara/hallucination_evaluation_model\""
      ],
      "metadata": {
        "id": "MNSyo5cFy_8r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tt = time.time()\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, trust_remote_code=True)\n",
        "print(f\"\\nTime taken to load model {model_id}: {int(time.time() - tt)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ8Ie5lRzAAw",
        "outputId": "024c20f6-8929-4315-dbd5-5eac959ed5fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time taken to load model vectara/hallucination_evaluation_model: 0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [ # Test data, List[Tuple[str, str]]\n",
        "    (\"The capital of France is Berlin.\", \"The capital of France is Paris.\"),\n",
        "    ('I am in California', 'I am in United States.'),\n",
        "    ('I am in United States', 'I am in California.'),\n",
        "    (\"A person on a horse jumps over a broken down airplane.\", \"A person is outdoors, on a horse.\"),\n",
        "    (\"A boy is jumping on skateboard in the middle of a red bridge.\", \"The boy skates down the sidewalk on a red bridge\"),\n",
        "    (\"A man with blond-hair, and a brown shirt drinking out of a public water fountain.\", \"A blond man wearing a brown shirt is reading a book.\"),\n",
        "    (\"Mark Wahlberg was a fan of Manny.\", \"Manny was a fan of Mark Wahlberg.\")\n",
        "]"
      ],
      "metadata": {
        "id": "NSejkMDZzAD5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the pairs\n",
        "prompt = \"<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: {text1}\\n\\nHypothesis: {text2}\""
      ],
      "metadata": {
        "id": "lV4toyHrzAGi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_pairs = [prompt.format(text1=pair[0], text2=pair[1]) for pair in pairs]\n",
        "input_pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzNlwU5UzAJU",
        "outputId": "e808d8c8-cda6-4df6-a843-d12feec29136"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: The capital of France is Berlin.\\n\\nHypothesis: The capital of France is Paris.',\n",
              " '<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: I am in California\\n\\nHypothesis: I am in United States.',\n",
              " '<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: I am in United States\\n\\nHypothesis: I am in California.',\n",
              " '<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: A person on a horse jumps over a broken down airplane.\\n\\nHypothesis: A person is outdoors, on a horse.',\n",
              " '<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: A boy is jumping on skateboard in the middle of a red bridge.\\n\\nHypothesis: The boy skates down the sidewalk on a red bridge',\n",
              " '<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: A man with blond-hair, and a brown shirt drinking out of a public water fountain.\\n\\nHypothesis: A blond man wearing a brown shirt is reading a book.',\n",
              " '<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: Mark Wahlberg was a fan of Manny.\\n\\nHypothesis: Manny was a fan of Mark Wahlberg.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use text-classification pipeline to predict\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model_id,  # 'vectara/hallucination_evaluation_model',\n",
        "    tokenizer=AutoTokenizer.from_pretrained('google/flan-t5-base'),\n",
        "    trust_remote_code=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Asc0FauzAMA",
        "outputId": "69471868-2859-4afb-d20a-3a3d78adf144"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_scores = classifier(input_pairs, top_k=None)  # List[List[Dict[str, float]]]"
      ],
      "metadata": {
        "id": "Jfn7JiGjzAOz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Extract the scores for the 'consistent' label\n",
        "simple_scores = [score_dict['score'] for score_for_both_labels in full_scores for score_dict in score_for_both_labels if score_dict['label'] == 'consistent']"
      ],
      "metadata": {
        "id": "x4Yv1gD2zARZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"simple_scores: {simple_scores}\")\n",
        "# Expected output: [0.011061512865126133, 0.6473632454872131, 0.1290171593427658, 0.8969419002532959, 0.18462494015693665, 0.005031010136008263, 0.05432349815964699]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt4cg3K1zAUS",
        "outputId": "3ebd3d87-adb8-4cb9-adeb-847690c730df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple_scores: [0.011061499826610088, 0.6473637223243713, 0.1290174126625061, 0.8969420790672302, 0.18462441861629486, 0.005031016655266285, 0.05432353541254997]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"full_scores: {full_scores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyzFVw1kzAW5",
        "outputId": "6409a039-7a06-4cb9-d756-7f305e47ffef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full_scores: [[{'label': 'hallucinated', 'score': 0.988938570022583}, {'label': 'consistent', 'score': 0.011061499826610088}], [{'label': 'consistent', 'score': 0.6473637223243713}, {'label': 'hallucinated', 'score': 0.3526362180709839}], [{'label': 'hallucinated', 'score': 0.8709826469421387}, {'label': 'consistent', 'score': 0.1290174126625061}], [{'label': 'consistent', 'score': 0.8969420790672302}, {'label': 'hallucinated', 'score': 0.1030578762292862}], [{'label': 'hallucinated', 'score': 0.815375566482544}, {'label': 'consistent', 'score': 0.18462441861629486}], [{'label': 'hallucinated', 'score': 0.9949689507484436}, {'label': 'consistent', 'score': 0.005031016655266285}], [{'label': 'hallucinated', 'score': 0.9456764459609985}, {'label': 'consistent', 'score': 0.05432353541254997}]]\n"
          ]
        }
      ]
    }
  ]
}